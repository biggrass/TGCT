\section{Introduction}
% Over the past decade, we have seen a tremendous rise in mobile applications. Given the fact that these applications are used to record and assist end users daily life, it becomes critical for developers to test Android applications and further improve software quality. However, testing on Android apps is becoming challenging due to the fragmentation issues of the Android platform\cite{b1}, the complexity of usage scenarios and the fast iteration of the Android platform.
Testing on Android apps is becoming challenging due to the fragmentation issues of the Android platform\cite{b1}, the complexity of usage scenarios and the fast iteration of the Android platform.
Crowdsourced testing was proposed to solve the problem of mobile application testing. It is that the requesters outsource the test tasks to different crowd workers, who fulfill the tasks and submit reports to the crowdsourced test platform. The platform integrates the reports and feeds them back to the requesters\cite{b2}. 

Based on the text of the test report, Wang et al.\cite{b3} proposed a clustering method for classifying test reports.
Starting from the screenshots of test reports, Feng et al.\cite{b9} use the image technology to analyze the screenshots, and assist in the priority ranking of test reports. From this, most of the crowdsourced testing work proposed by researchers focuses on the test reports. 
Owing to existing crowdsourced mechanism is not perfect, the post-processing work is very heavy. Based on such status, this paper proposed an optimization mechanism for crowdsourced testing. Begin with the root causes of the problem, we are committed to reducing unnecessary integration and processing efforts, and implementing efficient crowdsourced test.

% However, there are three inherent shortcomings of this test pattern. 1) Some crowd workers have lower professional skills, who need to be guided. 2) Some crowd workers prefer certain test cases. 3) There are some limitations in automated test results. 3) 

% Providing test guidance for crowd workers can optimize crowdsourced testing and alleviate the problems above\cite{b3}. 
According to the idea of collective intelligence\cite{b4}, we developed a framework named TGCT, which helps build the GUI model and take it to guide crowd workers to verify exceptions. To verify the effectiveness of TGCT, we selected and analyzed three Android applications to complete the controlled experiment. We analyze the effectiveness of the guide mechanism and the necessity of static source code analysis. Experiment shows that the tool-guided crowdsourced testing mechanism for mobile applications can effectively improve the quality of crowdsourced testing.

%to do%/
%In this paper, we mainly make the following contributions:1.We firstly propose a mechanism named TGCT, which apply guide mechanism to crowdsourced testing process. 2.Comparing the quality of the crowdsourced test results under the guide and non-guide mechanisms. 3.Evaluate the TGCT mechanism using real data from the perspective of test efficiency and code coverage.


